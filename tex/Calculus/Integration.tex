\documentclass[../MathsNotesBase.tex]{subfiles}




\date{\vspace{-6ex}}


\begin{document}	
	\searchableSection{Integration}{analysis, calculus, integration}
	\bigskip
	
	\searchableSubsection{Univariate Integration}{analysis, calculus, integration}{
		\biggerskip
		
		\subsubsection{The Riemann Integral}
		\boxeddefinition{In the context of the Riemann Integral, a \textbf{partition} of an interval ${ [a,b] \in \R{} }$ is a set,
			\[ P = \setc{x_i}{0 \leq i \leq n} \eqword{where} a \leq x_i < x_{i+1} \leq b. \]
			That's to say,
			\[ P = \{x_0, x_1, \dots, x_n\} \eqword{where} a = x_0 < x_1 < \cdots < x_n = b. \]
		}
		\boxeddefinition{The \textbf{lower estimate} of the area under the curve of a function $f(x)$ with respect to a particular partition is defined as,
			\[ L(P) = \sum_{i = 0}^{n-1} (x_{i+1} - x_i) \min_{ x_i \leq x \leq x_{i+1} }{ f(x) } \]
			where each ${ x_i \in P }$. The \textbf{upper estimate} is similarly defined as,
			\[ U(P) = \sum_{i = 0}^{n-1} (x_{i+1} - x_i) \max_{ x_i \leq x \leq x_{i+1} }{ f(x) }. \]
		}\label{def:lower-and-upper-estimates-of-area-under-curve}
		
		\boxeddefinition{Let $P(n)$ be a partition of cardinality $n+1$ over the interval $[a,b]$. If, for a function $f(x)$,
			\[ \lim_{n \to \infty} L(P(n)) = \lim_{n \to \infty} U(P(n)) = I \]
			then the \textbf{Riemann Integral} of $f(x)$ over $P(n)$ is defined as,
			\[ \int_a^b f(x) \dif x = I. \]
		}\label{def:riemann-integral}
	
		\bigskip
		\labeledProposition{Let $f$ and $g$ be integrable functions on an interval $[a,b]$ such that
			\[ \forall x \in [a,b] \logicsep f(x) \leq g(x). \]
			Then,
			\[ \int_a^b f(x) \dif x \leq \int_a^b g(x) \dif x. \]
		}{g-is-upper-bound-for-f-implies-integral-of-g-is-upper-bound-for-integral-of-f}
		\begin{proof}\nl[4]
			Since ${ \forall x \in [a,b] \logicsep f(x) \leq g(x) }$ then, for any ${ a \leq x_1 < x_2 \leq b }$,
			\[ \min_{ x_1 \leq x \leq x_2 } f(x) \leq \min_{ x_1 \leq x \leq x_2 } g(x) \eqand \max_{ x_1 \leq x \leq x_2 } f(x) \leq \max_{ x_1 \leq x \leq x_2 } g(x). \]
			Therefore, if ${ L_f(P(n)), U_f(P(n)) }$ is the lower and upper estimates (\ref{def:lower-and-upper-estimates-of-area-under-curve}) of the area under the curve of $f(x)$ and similarly ${ L_g(P(n)), U_g(P(n)) }$, then we must have,
			\[ \lim_{n \to \infty} L_f(P(n)) \leq \lim_{n \to \infty} L_g(P(n)) \eqand \lim_{n \to \infty} U_f(P(n)) \leq \lim_{n \to \infty} U_g(P(n)). \]
			It follows then, that the Riemann Integral (\ref{def:riemann-integral}) of $f(x)$ over the interval $[a,b]$ must be less than or equal to that of $g(x)$ over the same interval.
		\end{proof}
		\smallskip
		\begin{corollary}\label{coro:g-is-lower-bound-for-f-implies-integral-of-g-is-lower-bound-for-integral-of-f}
			Let $f$ and $g$ be integrable functions on an interval $[a,b]$ such that
				\[ \forall x \in [a,b] \logicsep f(x) \geq g(x). \]
			Then,
				\[ \int_a^b f(x) \dif x \geq \int_a^b g(x) \dif x. \]
		\end{corollary}
		\begin{proof}\nl[4]
			By \autoref{prop:g-is-upper-bound-for-f-implies-integral-of-g-is-upper-bound-for-integral-of-f}, since
			\[ \forall x \in [a,b] \logicsep f(x) \geq g(x) \iff \forall x \in [a,b] \logicsep -f(x) \leq -g(x) \]
			we therefore have,
			\[\begin{aligned}
				&&\int_a^b -f(x) \dif x &\leq \int_a^b -g(x) \dif x \nn
				&\iff & -\int_a^b f(x) \dif x &\leq -\int_a^b g(x) \dif x &\sidecomment{by linearity of integration} \nn
				&\iff & \int_a^b f(x) \dif x &\geq \int_a^b g(x) \dif x. \qedhere
			\end{aligned}\]
		\end{proof}
		
		
		\sep
		\begin{exe}
			\item{Suppose ${ f(x) = e^x }$ and we define a partition over the interval $[0,1]$,
				\[ P(n) = \{0, \frac{1}{n}, \frac{2}{n}, \dots, \frac{n-1}{n}, 1\}. \]
				Then the lower estimate of the area under the curve of this function is given by,
				\begin{align*}
					L(P(n)) &= \sum_{i=0}^{n-1} (x_{i+1} - x_i) \min_{ x_i \leq x \leq x_{i+1} }{ f(x) } \nn
					&= \frac{1}{n} \sum_{i=0}^{n-1} \min_{ \frac{i}{n} \leq x \leq \frac{i+1}{n} }{ e^x } \nn
					&= \frac{1}{n} \sum_{i=0}^{n-1} e^{\frac{i}{n}} = \frac{1}{n} (1 + e^{\frac{1}{n}} + \cdots + e^{\frac{n-1}{n}}) \nn
					&= \frac{1}{n} \left( \frac{e - 1}{e^{\frac{1}{n}} - 1} \right).\\
				\end{align*}
				Meanwhile, the upper estimate is given by,
				\begin{align*}
					U(P(n)) &= \frac{1}{n} \sum_{i=0}^{n-1} \max_{ \frac{i}{n} \leq x \leq \frac{i+1}{n} }{ e^x } \nn
					&= \frac{1}{n} \sum_{i=0}^{n-1} e^{\frac{i+1}{n}} = \frac{1}{n} (e^{\frac{1}{n}} + \cdots + e^{\frac{n-1}{n}} + e) \nn
					&= \frac{e^{\frac{1}{n}}}{n} \left( \frac{e - 1}{e^{\frac{1}{n}} - 1} \right).\\
				\end{align*}
				Taking the limits as ${ n \to \infty }$,
				\begin{align*}
					\lim_{n \to \infty} L(P(n)) &= \lim_{n \to \infty} \frac{1}{n} \left( \frac{e - 1}{e^{\frac{1}{n}} - 1} \right) \nn
					&= (e - 1) \lim_{n \to \infty} \frac{1}{n} \left( \frac{1}{e^{\frac{1}{n}} - 1} \right)  &\sidecomment{} \nn
					&= (e - 1) \lim_{n \to \infty} \frac{1/n}{e^{\frac{1}{n}} - 1}  &\sidecomment{} \nn
					&= (e - 1) \lim_{n \to \infty} \frac{-1/n^2}{(-1/n^2)e^{\frac{1}{n}}}  &\sidecomment{by L'H\^{o}pital} \nn
					&= (e - 1) \lim_{n \to \infty} e^{-\frac{1}{n}} = (e - 1)(1) = e - 1,
				\end{align*}
				\begin{align*}
					\lim_{n \to \infty} U(P(n)) &= \lim_{n \to \infty} \frac{e^{\frac{1}{n}}}{n} \left( \frac{e - 1}{e^{\frac{1}{n}} - 1} \right) \nn
					&= (e - 1) \lim_{n \to \infty} \frac{e^{\frac{1}{n}}}{n} \left( \frac{1}{e^{\frac{1}{n}} - 1} \right) \nn
					&= (e - 1) \left( \lim_{n \to \infty} e^{\frac{1}{n}} \right) \left( \lim_{n \to \infty} \frac{1}{n} \left[ \frac{1}{e^{\frac{1}{n}} - 1} \right) \right] \nn
					&= (e - 1) (1) (1) = e - 1. \\
				\end{align*}
				So, we see that 
				\[ \lim_{n \to \infty} L(P(n)) = \lim_{n \to \infty} U(P(n)) = e - 1 \]
				and this is the value of the riemann integral for $e^x$ over the interval $[0,1]$. Note that it is in agreement with the analytic solution,
				\begin{align*}
					\int_0^1 e^x &= [e^x]_0^1 \\
					&= e^1 - e^0 = e - 1.
				\end{align*}
			}
		\end{exe}
		
		\biggerskip
		\subsubsection{FTC and the Chain Rule}
		\begin{align*}
			&\hspace{14pt} \dod{}{t} \int_{p(t)}^{q(t)} f(x) \dif x \nn
			&= \dod{}{t} \int_0^{q(t)} f(x) \dif x - \dod{}{t} \int_0^{p(t)} f(x) \dif x &\sidecomment{} \nn
			&= \dod{q}{t} \dod{}{q} \int_0^{q} f(x) \dif x - \dod{p}{t} \dod{}{p} \int_0^{p} f(x) \dif x &\sidecomment{} \nn
			&= \dod{q}{t} f(q) - \dod{p}{t} f(p).
		\end{align*}
		
		\bigskip
		\subsubsection{Definite and Indefinite Integration}\label{ssection:definite-and-indefinite-integration}
		Indefinite integration determines an antiderivative up to a constant so that, if $F(x)$ is some antiderivative of $f(x)$ and $C$ is a constant, then
		\[ \int f(x) \dif x = F(x) + C. \]
		This expresses the fact that any value of $C$ would produce a valid antiderivative of $f(x)$. In fact, these are the fibres -- the cosets of the kernel -- of the differentiation linear transformation. The kernel of differentiation is the set of constant-valued functions,
		\[ f(x) = C \]
		for any ${ C \in \R{} }$.\\
		
		In the case of a definite integral, however, the constant cancels out:
		\[ \int_a^b f(x) \dif x = [F(x) + C]_a^b = (F(b) + C) - (F(a) + C) = F(b) - F(a) \]
		so that we are able to resolve the value of the definite integral to a specific constant value. In this case, the result is the sum of two elements of the kernel of the differentiation transform and so the result is also in the kernel.\\
		
		However, if we consider a function of a variable, $t$, such that
		\[ h(t) = \int_a^t f(x) \dif x \]
		then $h(t)$ is also an antiderivative of $f(t)$ but also,
		\[ h(t) = \int_a^t f(x) \dif x = [F(x) + C]_a^t = F(t) - F(a) = F(t) + C_2 \]
		where ${ C_2 = -F(a) }$ is a constant. So, the definite integral -- specifically, the initial value, $a$ -- has allowed us to resolve a particular antiderivative from the set of functions produced by the possible values of $C$. That's to say, the initial value $a$ specified for us a particular element in the kernel of the differentiation operator -- namely, ${ C_2 = -F(a) }$.\\
		
		Furthermore, since the definite integral is a particular antiderivative of $f(x)$ we can also relate the indefinite and definite integrals as follows,
		\[ \int f(x) \dif x = \int_a^t f(x) \dif x + C. \]
		This amounts to -- expressed in terms of group theory -- the statement that, if $G$ is a group with kernel $K$ and ${ x,k \in G,\; k \in K }$, then
		\[ xK = xkK \] 
		where 
		\begin{align*}
			xK &= \int f(x) \dif x = F(x) + C \\
			xk &= \int_a^t f(x) \dif x = F(t) - F(a) \\
			xkK &= \int_a^t f(x) \dif x + C = F(t) - F(a) + C.
		\end{align*}
	
	
		\bigskip
		\subsubsection{Change of Variable}
		\bigskip
		There are two types of variable substitution.
		\begin{itemize}
			\item{Substitution: ${ x = g(u) }$,
				\[ \int_a^b f(x) \dif x = \int_a^b f(g(u)) \dif\, (g(u)) = \int_{\inv{g}(a)}^{\inv{g}(b)} f(g(u)) g'(u) \dif u. \]
				
				For example, making the substitution ${ x = \sin\theta }$ in,
				\[\begin{aligned}
					\int_0^1 \frac{1}{\sqrt{1 - x^2}} \dif x &= \int_0^1 \frac{1}{\sqrt{1 - \sin^2\theta}} \dif\, (\sin\theta) \nnn
					&= \int_{\inv{\sin}(0)}^{\inv{\sin}(1)} \frac{1}{\sqrt{1 - \sin^2\theta}} \cos\theta \dif \theta &\sidecomment{} \nnn
					&= \int_0^{\frac{\pi}{2}} \frac{1}{\sqrt{1 - \sin^2\theta}} \cos\theta \dif \theta &\sidecomment{} \nnn
					&= \int_0^{\frac{\pi}{2}} \dif \theta = \frac{\pi}{2}.
				\end{aligned}\]	
			}
			\bigskip
			\item{"Reverse" Substitution: ${ u = g(x) }$,
				\[ \int_a^b f(x) \dif x = \int_{g(a)}^{g(b)} f(x) \frac{1}{g'(x)} \dif u. \]
				
				For example, making the substitution ${ u = \frac{x}{a} }$ in,
				\[ \int_a^{at} f(x) \dif x = \int_1^t f(au) a \dif u = a \int_1^t f(au) \dif u. \]
			}
		\end{itemize}
	
	
		\pagebreak
		\subsubsection{Improper Integrals}
		\bigskip
		\boxeddefinition{\textbf{(Improper Integral)} An integral is called \textit{improper} if the interval it is defined over is half-open. That's to say, if either of the interval bounds $a$ or $b$ in the integral
			\[ \int_a^b f(t) \dif t \]
		is infinity or the function is undefined at that point. The value of such an integral is defined as, if we take the case where the interval is open at the upper bound,
			\[ \int_a^b f(t) \dif t = \lim_{x \to b} \, \int_a^x f(t) \dif t. \]
		
		\nl[6]	
		More precisely, if the integrand function is undefined at the point ${ t = b }$ then
			\[ \int_a^b f(t) \dif t = \lim_{x \to b^-} \, \int_a^x f(t) \dif t \]
		and if the function is undefined at the point ${ t = a }$ then
			\[ \int_a^b f(t) \dif t = \lim_{x \to a^+} \, \int_x^b f(t) \dif t. \]
		Meanwhile if ${ b = \infty }$ then
			\[ \int_a^b f(t) \dif t = \int_a^\infty f(t) \dif t = \lim_{x \to \infty} \, \int_a^x f(t) \dif t \]
		and similarly if ${ a = -\infty }$ then
		\[ \int_a^b f(t) \dif t = \int_{-\infty}^b f(t) \dif t = \lim_{x \to -\infty} \, \int_x^b f(t) \dif t. \]
		}
	
		\note{An integral over an interval that is open at both ends such as,
			 \[ \int_{-\infty}^\infty f(t) \dif t \]
			 is defined as the sum of two improper integrals over the half-open intervals,
			 \[ \int_{-\infty}^\infty f(t) \dif t = \int_0^\infty f(t) \dif t + \int_{-\infty}^0 f(t) \dif t. \]
			 If either of the two summand integrals diverges, then their sum is defined as divergent. The result of this is that, even if the integrand is an odd function so that for all ${ a > 0 \in \R{} }$,
			 \[ \int_{-a}^a f(t) \dif t = 0, \]
			 the integral
			 \[ \int_{-\infty}^\infty f(t) \dif t \]
			 may (or may not) be defined as divergent. The reason for this is that, although if the upper and lower bounds go to infinity at the same rate (as in the case of $a$ and $-a$), then we indeed have a limit of 0, this is not true if the bounds are allowed to vary independently. If the bounds vary independently then the value of the integral depends on the rate at which the bounds go to infinity. This causes a problem for the definition of the Riemann Integral and so these integrals are commonly defined to be divergent (see example \ref{ex:symmetric-improper-integral-of-odd-function}).\\
			 However, in some circumstances (most notably distribution theory), another definition of the integral may be used: the Lebesgue Integral with the Cauchy Principal Value (see: \href{https://en.wikipedia.org/wiki/Cauchy_principal_value}{wikipedia}).
		}

		
		\bigskip
		\labeledTheorem{\textbf{(Direct Comparison Test)} If ${ 0 \leq f(t) \leq g(t) }$ for all ${ t > T \in \R{} }$ then
			\[ \int_T^\infty g(t) \dif t \text{ converges } \implies \int_T^\infty f(t) \dif t \text{ converges } \]
			and if ${ 0 \leq g(t) \leq f(t) }$ for all ${ t > T \in \R{} }$ then
			\[ \int_T^\infty g(t) \dif t \text{ diverges } \implies \int_T^\infty f(t) \dif t \text{ diverges. } \]
		}{integral-direct-comparison-test}
		\begin{proof}\nl[4]
			By \autoref{prop:g-is-upper-bound-for-f-implies-integral-of-g-is-upper-bound-for-integral-of-f}, we have that, if ${ 0 \leq f(t) \leq g(t) }$ for all ${ t > T \in \R{} }$ then,
			\[ \int_T^\infty f(t) \dif t \leq \int_T^\infty g(t) \dif t \]
			and so, if the integral of $g$ over this interval is finite then so must the integral of $f$ be also.\\
			
			Also, by \autoref{coro:g-is-lower-bound-for-f-implies-integral-of-g-is-lower-bound-for-integral-of-f}, if ${ 0 \leq g(t) \leq f(t) }$ for all ${ t > T \in \R{} }$ then,
			\[ \int_T^\infty f(t) \dif t \geq \int_T^\infty g(t) \dif t \]
			and so, if the integral of $g$ over this interval is infinite then so must the integral of $f$ be also.
		\end{proof}
	
		\medskip
		\begin{corollary}
			If $f$ is an integrable function and is lower bounded on ${ [a,\infty) }$ by ${ c > 0 \in \R{} }$ such that 
			\[ \forall x \in [a,b] \logicsep f(x) \geq c, \]
			then
			\[ \int_a^\infty f(x) \dif x \text{ diverges. } \]
		\end{corollary}
		\begin{proof}
			Since
			\[ \int_a^\infty c \dif x = c \int_a^\infty \dif x = c [x]_a^\infty = \infty \]
			diverges, \autoref{theo:integral-direct-comparison-test} tells us that the integral of $f$ also diverges.
		\end{proof}
	
		\medskip
		\begin{corollary}
			If $f$ and $g$ are non-negative integrable functions and on ${ [a,\infty) }$ we have
			\[ \int_a^\infty f(x) \dif x \text{ converges } \]
			and, for some ${ M \geq 0 }$,
			\[ g(x) \leq M, \]
			then
			\[ \int_a^\infty f(x)g(x) \dif x \text{ converges. } \]
		\end{corollary}
		\begin{proof}
			If the integral of $f$ over the interval converges then it must evaluate to a finite value and we can therefore also deduce that
			\[ M\int_a^\infty f(x) \dif x = \int_a^\infty Mf(x) \dif x \text{ converges. } \]
			Since, for ${ x \in [a,\infty) }$,
			\[ f(x)g(x) \leq Mf(x) \]
			we can therefore use \autoref{theo:integral-direct-comparison-test} to reason that
			\[ \int_a^\infty f(x)g(x) \dif x \text{ converges. } \qedhere \]
		\end{proof}
	
		\bigskip
		\labeledProposition{
			\[ \int_1^\infty f(x) \dif x \text{ converges } \implies \int_1^\infty f(x^2) \dif x \text{ converges } \]
			but
			\[ \int_1^\infty f(x^2) \dif x \text{ converges } \centernot\implies \int_1^\infty f(x) \dif x \text{ converges. } \]
		}{}
		\begin{proof}\nl[4]
			\[\begin{aligned}
				\int_1^\infty f(x) \dif x &= \int_1^\infty f(u^2) \dif\, (u^2) \nn
				&= \int_1^\infty f(u^2) 2u \dif u \nn
				&\therefore \int_1^\infty f(u^2) 2u \dif u \text{ converges. } \nn
			\end{aligned}\]
			Since, for ${ u \in [1,\infty) }$, we have ${ f(u^2) 2u \geq f(u^2) }$, by \autoref{theo:integral-direct-comparison-test},
			\[ \int_1^\infty f(u^2) \dif u \text{ converges. } \]
			
			Clearly then also, the convergence of $f(x^2)$ over the same interval doesn't allow us to draw any such similar conclusion about the convergence of $f(x)$. For example, let $f$ be the function ${ f(t) = 1/t }$. Then,
			\[ \int_1^\infty f(x^2) \dif x \text{ converges } \]
			but
			\[ \int_1^\infty f(x) \dif x \text{ diverges. }  \qedhere \]
		\end{proof}
	
		\bigskip
		\labeledTheorem{\textbf{(Limit Comparison Test)} If $f(t)$ and $g(t)$ are both positive for all ${ t \geq a }$ then, for the test value
			\[ T = \lim_{t \to \infty} \frac{f(t)}{g(t)}, \]
			\begin{itemize}
				\item{if ${ T = 1 }$ then
					\[ \int_a^\infty f(t) \dif t \text{ converges } \iff \int_a^\infty g(t) \dif t \text{ converges; } \]
				}
				\item{if ${ T = 0 }$ then
					\[ \int_a^\infty g(t) \dif t \text{ converges } \implies \int_a^\infty f(t) \dif t \text{ converges. } \]
				}
			\end{itemize}	
		}{}
		\begin{proof}\nl[4]
			\TODO{reference relevant theorem in Analysis}\\
			\TODO{add notes in Calculus about algebra of limits of functions \wrt when we take the limit of a fraction where one or both of the numerator and denominator are going infinite (and so we can't apply the algebra of limits until we have transformed it to a ratio of finite limits).}\\
			
		\end{proof}
		\TODO{note about limit of ratio being 1 not being equivalent to the numerator and denominator having the same limit: that applies when the limits are finite and non-zero but if they are zero or infinite then the limit of the ratio gives indication of speed of going to zero or infinity. ref: L'Hopital's rule.}
		\note{Note that if the limits of $f(t)$ and $g(t)$ as ${ t \to \infty }$ are both finite and non-zero then we have case (vi) of \autoref{prop:func-finite-limit-algebra} where the limit of the ratio is simply the ratio of the limits of $f(t)$ and $g(t)$. Also, if one of the limits is finite and non-zero and the other is tending to zero or infinity then the limit is just as we would expect from the limits of e.g. polynomial fractions. That's to say, a finite numerator over a denominator that's tending to zero results in an infinite limit and if the denominator is tending to infinity then the result is a limit of zero.\\\\ However, if both limits are zero or infinite then we need to employ L'H\^{o}pital's rule to obtain the limit of the ratio (see: \href{https://web.ma.utexas.edu/users/m408n/m408c/CurrentWeb/LM4-4-11.php}{UTexas}). So, in each case, the result of the limit of the ratio is an indicator of whether the numerator or denominator is going to infinity or zero faster or slower than the numerator. \question{Do we have a problem if e.g. the numerator is going to zero while the denominator is going to infinity?}}
	
	
		\sep
		\begin{exe}
			\ex{${\bm{ \int_1^\infty \frac{1}{x + 1} \dif x }}$:\\
				 
				 This integral does not converge despite the integrand ${ \frac{1}{x + 1} \leq \frac{1}{x} }$ for all $x$ over the integration. However, ${ \int_1^\infty \frac{1}{x^{3/2}} \dif x }$ does converge.
			}
			\bigskip
			\ex{${\bm{ \int_1^\infty \frac{\pi}{2} - \inv{\tan}(x) \dif x }}$:\\
				
				This integral diverges because, if we use L'Hopital's rule to take the limit
				\[\begin{aligned}
					\lim_{x \to \infty} \frac{\frac{\pi}{2} - \inv{\tan}(x)}{\frac{1}{x}} &= \lim_{x \to \infty} \frac{-\frac{1}{1 + x^2}}{-\frac{1}{x^2}} \nn
					&= \lim_{x \to \infty} \frac{x^2}{1 + x^2} &\sidecomment{} \nn
					&= \lim_{x \to \infty} \frac{1}{\frac{1}{x^2} + 1} = 1.
				\end{aligned}\]
				So, the integral exhibits the same behaviour at infinity as ${ \int_1^\infty \frac{1}{x} \dif x }$ which diverges. \addref
			}
			\bigskip
			\ex{${\bm{ \int_2^\infty \frac{1}{x(\ln(x))^r} \dif x }}$:\\
				
				This integral converges for all ${ r > 1 \in \R{} }$ because
				\[ \int_2^\infty \frac{1}{x(\ln(x))^r} \dif x = \int_{\ln{2}}^\infty \frac{1}{(\ln(x))^r} \dif\, (\ln{x}) \]
				and so, for ${ u(x) = \ln(x) }$ we have
				\[ \int_{\ln{2}}^\infty \frac{1}{u^r} \dif u  \]
				which, by \addref, converges for ${ r > 1 }$.
			}
			\bigskip
			\ex{${\bm{ \int_1^\infty \frac{1}{\sqrt{x^4 + x^3} - x^2} \dif x }}$:\\
							
				Observe that
				\[\begin{aligned}
					\frac{1}{\sqrt{x^4 + x^3} - x^2} &= \frac{1}{\sqrt{x^4 + x^3} - x^2} \cdot \frac{\sqrt{x^4 + x^3} + x^2}{\sqrt{x^4 + x^3} + x^2} \nn
					&= \frac{\sqrt{x^4 + x^3} + x^2}{x^3} \nn
					&= \frac{\sqrt{x^4(1 + \frac{1}{x})} + x^2}{x^3} \nn
					&= \frac{x^2((1 + \frac{1}{x}) + 1)}{x^3} \nn
					&= \frac{(1 + \frac{1}{x}) + 1}{x}.
				\end{aligned}\]
				We can guess that this will behave asymptotically similarly to ${ \frac{2}{x} }$ and so we perform the ratio test \addref,
				\[ \frac{ \frac{(1 + \frac{1}{x}) + 1}{x} }{ \frac{2}{x} } = \frac{(1 + \frac{1}{x}) + 1}{2} \to 1 \eqword{as} x \to \infty. \]
				Therefore, the integral behaves similarly to
				\[ \int_1^\infty \frac{2}{x} \dif x = 2 \int_1^\infty \frac{1}{x} \dif x \]
				which diverges by the divergence of ${ \int_1^\infty \frac{1}{x} \dif x }$ (\addref).
			}
			\bigskip
			\ex{${\bm{ \int_{-\infty}^\infty \frac{x}{1 + x^2} \dif x }}$:\\
				
				This is an example of a symmetric improper integral of an odd function such that, for all ${ a > 0 \in \R{} }$,
				\[ \int_{-a}^a \frac{x}{1 + x^2} \dif x = 0. \]
				But this integral is defined to be the sum of the limits,
				\[ \lim_{a_1 \to -\infty, \, a_2 \to \infty} \left( \int_{a_1}^0 \frac{x}{1 + x^2} \dif x + \int_0^{a_2} \frac{x}{1 + x^2} \dif x \right) \]
				and since both the summands are infinite and have no defined limit, the sum is also undefined. Therefore, the Riemann Integral is undefined (or divergent).
			}\label{ex:symmetric-improper-integral-of-odd-function}
		\end{exe}
	}


% ------------------------ break --------------

	\pagebreak
	\searchableSubsection{Multivariate Integration}{analysis, calculus, integration}{
		
		\bigskip
		\subsubsection{Partial Differentiation of Integrals}
		\[ \dpd{}{x} \left( \int f(x,y) \dif y \right) = \int \dpd{f(x,y)}{x} \dif y \]
		
		\bigskip
		\subsubsection{Integration of Partial Derivatives}
		Suppose we have a function ${ f(x,y) }$. Then,
		\[ \int \dpd{f(x,y)}{x} \dif x = g(x,y) + C(y) \eqand \int \dpd{f(x,y)}{y} \dif x = g(x,y) + C(x). \]
		So, the antiderivatives are only determined upto a function of the other variable. In this case, we can recover the original function $f(x,y)$ if we have both partial derivatives by setting the antiderivatives equal,
		\[ g_1(x,y) + C_1(y) = g_2(x,y) + C_2(x). \]
		Any cross terms (terms containing both $x$ and $y$) in $f$ will appear in both $g_1(x,y)$ and $g_2(x,y)$ and the remaining term in $g_1$ will be equal to $C_2$ while the remaining term in $g_2$ will be equal to $C_1$.\\
		
		\medskip
		\subsubsubsection{Example}
		\begin{exe}
			\item{
				Let $\varphi: \mathbb{R}^{2} \rightarrow \mathbb{R}$ be such that for all $(x, y) \in \mathbb{R}^{2}$ the following equalities hold:
				\[
				\frac{\partial \varphi}{\partial x}(x, y)=\underbrace{e^{x} \sin (y)}_{f(x, y)} \; \wedge \; \frac{\partial \varphi}{\partial y}(x, y)=\underbrace{e^{x} \cos (y)}_{g(x, y)}.
				\]
				Integrating $f$ with respect to $x$ we get
				\[ \varphi(x, y)=\int e^{x} \sin (y) d x=e^{x} \sin (y)+\psi(y), \]
				for some differentiable function $\psi: \mathbb{R} \rightarrow \mathbb{R}$. Differentiating with respect to $y$ it follows that 
				\[ e^{x} \cos (y)+\psi^{\prime}(y)=g(x, y)=e^{x} \cos (y). \]
				Therefore $\psi^{\prime}$ is always 0 and it follows that there exists $C \in \mathbb{R}$ such that for all $u \in \mathbb{R}$ we have $\psi(u)=C$ -- that is, $\psi$ is constant.\\
				This gives you $\varphi(x, y)=e^{x} \sin (y)+C \in \mathbb{R},$ for some $C \in \mathbb{R}$. Taking $C \in \mathbb{R}$ arbitrarily will give you a possible $\varphi$.
			}
		\end{exe}
	
		\sep
		
		In the case of definite integration though, whether the variables are independent is important (?). For example, suppose ${ y = y(x) }$. Refer: \url{https://math.stackexchange.com/questions/754742/integrating-a-partial-derivative} and \url{https://math.stackexchange.com/questions/2714061/integrating-partial-derivatives?noredirect=1&lq=1}.
		
		\begin{itemize}
			\item{If ${ y = y(x) }$ then the result of the integral may not be meaningful.}
			\item{If we have both of the partial derivatives (wrt. $x$ and $y$), then we can recover the original function regardless of whether the variables are independent or not.}
		\end{itemize}
	}

\end{document}